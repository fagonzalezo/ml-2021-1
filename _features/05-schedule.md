---
id: schedule
name: Schedule
heading: Course schedule
subheading: 
image: 
---
<table class="table table-condensed">
	<tbody>
		<tr>
			<th>Week</th>
			<th>Topic</th>
			<th>Material</th>
			<th>Assignments</th>
		</tr>
		<tr>
			<td>Feb 23-Mar 2</td>
			<td>1.1 Introduction</td>
			<td>
				<a href= "https://drive.google.com/file/d/1nZ25mVOFvWkLwvqVL8Wpf0xQR-vWNFV0/view?usp=sharing">Class video 23/02/2021</a><br>
				<a href= "https://drive.google.com/file/d/1F_-FxUdhE7zioW1awuvu15BX_x16BtZV/view?usp=sharing">Class video 25/02/2021</a><br>
				<a href= "https://drive.google.com/file/d/15cHrAneUhEJpX-iHEophkfLiRuSavU9t/view?usp=sharing">Class video 02/03/2021</a><br>
				Fabio González, Brief Introduction to ML (<a href= "introduction ml.pdf">slides</a>)<br>
				<a href= "http://videolectures.net/bootcamp07_keller_bss/">Linear Algebra and Probability Review</a> (part 1 Linear Algebra, part 2 Probability)
			</td>
			<td>
				<a href= "assign1.pdf">Assignment 1</a>
			</td>
		</tr>
		<tr>
			<td>Mar 9</td>
			<td>1.2 Bayesian decision theory</td>
			<td>
				[Alp14] Chap 3 (<a href= "https://www.cmpe.boun.edu.tr/~ethem/i2ml3e/3e_v1-0/i2ml3e-chap3.pdf">slides</a>) <br>
			</td>
			<td>
			</td>
		</tr>
		<tr>
			<td>Mar 16</td>
			<td>1.3 Estimation</td>
			<td>
				[Alp10] Chap 4, 5 (<a href= "https://www.cmpe.boun.edu.tr/~ethem/i2ml3e/3e_v1-0/i2ml3e-chap4.pdf">slides</a>)<br>
				Bias and variance (<a href= "http://nbviewer.ipython.org/6788818">Jupyter notebook</a>)<br>
			</td>
			<td>
			</td>
		</tr>
		<tr>
			<td>
				Mar 23<br>
			</td>
			<td>1.5 Design and analysis of ML experiments</td>
			<td>
				[Alp10] Chap 19 (<a href= "http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/2e_v1-0/i2ml2e-chap19-v1-0.pdf">slides</a>) <br>
			</td>
			<td>
			</td>
		</tr>
		<tr>
			<td>Apr 6</td>
			<td>2.1 Kernel methods basics</td>
			<td>
				Introduction to kernel methods (<a href= "https://fagonzalezo.github.io/ml-2016-2/kernels.pdf">slides</a>) <br>
				[Alp10] Chap 13 (<a href= "http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/2e_v1-0/i2ml2e-chap13-v1-0.pdf">slides</a>)<br>
			</td>
			<td>
			</td>
		</tr>
		<tr>
			<td>Apr 13-20</td>
			<td>2.2 Support vector learning</td>
			<td>
				[Alp10] Chap 13 (<a href= "http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/2e_v1-0/i2ml2e-chap13-v1-0.pdf">slides</a>)<br>
				<a href="http://axiom.anu.edu.au/%7Edaa/courses/GSAC6017/tekbac_4.pdf">An
					introduction to ML</a>, Smola <br>
				<a href="http://www1.cs.columbia.edu/%7Ekathy/cs4701/documents/jason_svm_tutorial.pdf">Support
					Vector Machine Tutorial</a>, Weston<br>
				Máquinas de vectores de soporte y selección de modelos (<a href="https://drive.google.com/file/d/1X4b_5FMHDs7EtbwPzw7YDeMF5V4pqoer/view?usp=sharing">Jupyter Notebook</a>)<br>
			</td>
			<td>
			</td>
		</tr>
		<tr>
			<td>Apr 27</td>
			<td>3.1 Neural network basics </td>
			<td>
				[Alp10] Chap 11 (<a href= "http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/2e_v1-0/i2ml2e-chap11-v1-0.pdf">slides</a>)<br>
				Quick and dirty introduction to neural networks (<a href= "https://gist.github.com/fagonzalezo/c1f56629890dcf5670aa">Jupyter notebook</a>)<br>
				<a href= "https://fagonzalezo.github.io/ml-2018-1/backpropagation.pdf">Backpropagation derivation handout</a>
			</td>
			<td>
			</td>
		</tr>
		<tr>
			<td>
				May 4 
			</td>
			<td>
			3.2 Deep learning <br>
			</td>
			<td>
				Representation Learning and Deep Learning (<a href= "https://github.com/fagonzalezo/dl_tutorial_upv/raw/gh-pages/UPV-dl.pdf">slides</a>)<br>
				<a href= "https://fagonzalezo.github.io/dl_tutorial_upv/">Representation Learning and Deep Learning Tutorial</a> <br>
			</td>
			<td>
			</td>
		</tr>
		<tr>
			<td>May 11</td>
			<td>3.2 Deep learning</td>
			<td>
				Deep learning frameworks (<a href= "ML Deep Learning Frameworks.pdf">slides</a>)<br>
				Introduction to TensorFlow (<a href= "https://colab.research.google.com/drive/1cjmAU2v0oDZawN9AAZshz4t6AhqDOBf-">Jupyter notebook</a>)<br>
				Neural Networks in Keras (<a href= "https://colab.research.google.com/drive/1iOIVyQ19GGkY_5knuLRo0HP3BouJlpwy">Jupyter notebook</a>)<br>
			</td>
			<td>
			</td>
		</tr>
		<tr>
			<td>May 18</td>
			<td>3.3 Convolutional neural networks</td>
			<td>
				CNN for image classification in Keras (<a href= "https://colab.research.google.com/drive/1Wb94CUIJdB1Z-S6mFhxsxB4v6SzmF7sN">Jupyter notebook</a>)<br>
				<a href= "https://cs.stanford.edu/people/karpathy/convnetjs/">ConvNetJS demos</a><br>
				<a href= "https://distill.pub/2017/feature-visualization/">Feature visualization</a><br>
			</td>
			<td>
			</td>
		</tr>
		<tr>
			<td>May 25</td>
			<td>3.4 Recurrent neural networks</td>
			<td>
				<a href= "https://drive.google.com/file/d/1exxGq3X1mDHqhMMDiA0Q_mhqy0MvpE8U/view?usp=sharing">Class video 4/06/2020</a><br>
				<a href= "https://drive.google.com/file/d/1hU7w32avFaa2BaYymSIwRoty9l5wbiB0/view?usp=sharing">Class video 9/06/2020</a><br>
				<a href= "https://colab.research.google.com/drive/1bs4_l2ZA-uJYdvrOZpWgb8ItDg1PRKft?usp=sharing">CNN for text classification handout</a> <br>
				<a href= "https://colab.research.google.com/drive/1DbCuNqQ8wwDAqnWJxrEnyKey_zgWD-5p?usp=sharing">LSTM language model handout</a> <br>
			</td>
			<td>
			</td>
		</tr>
		<tr>
			<td>Jun 1</td>
			<td>3.5 Deep generative models</td>
			<td>Alexander Amini, Deep generative models (<a href="http://introtodeeplearning.com/2019/materials/2019_6S191_L4.pdf">slides</a>, <a href= "https://www.youtube.com/watch?v=yFBFl1cLYx8&index=1&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI">video</a>) (from <a href= "http://introtodeeplearning.com">MIT 6.S191</a>)<br>
			Deep generative models (<a href= "https://drive.google.com/file/d/10mZlO1b6zPfCig9bc-mKHPqP84ldCTeG/view?usp=sharing">Jupyter notebook</a>)
			</td>
			<td>
			</td>
		</tr>
		<tr>
			<td>Jun 8</td>
			<td>4.1 Bayesian Methods<br>
			4.2 Monte Carlo inference</td>
			<td>
			Radford M. Neal, Bayesian Methods for Machine Learning (<a href= "https://www.cs.toronto.edu/~radford/ftp/bayes-tut.pdf">slides</a>)<br>
			Beery et al., Markov Chain Monte Carlo for Machine Learning, Adv Topics in ML, Caltech (<a href= "https://taehwanptl.github.io/lectures/lecture_04_20.pdf">slides</a>)<br>
			Alex Rogozhnikov, <a href= "https://taehwanptl.github.io/lectures/lecture_04_20.pdf">Hamiltonian Monte Carlo explained
			</a>
			</td>
			<td>
			</td>
		</tr>
		<tr>
			<td>Jun 15</td>
			<td>4.3 Variational Bayes</td>
			<td>
			<a href= "https://colab.research.google.com/drive/1xIC_Y5T7IwkJz0SNQyRSlRfDf2fDRvbv">Variational Bayes in Tensorflow</a> <br>
			<a href= "https://colab.research.google.com/drive/1xX11qB8Ls9t_wuvRYHQp1_v-qBImVkt1">Variational Autoencoders in Tensorflow</a> <br>
			</td>
			<td>
			</td>
		</tr>
	</tbody>
</table>
